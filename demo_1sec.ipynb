{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Search Demo\n",
    "Similarity Search demo through audio-to-audio as well as the text-to-audio search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuhuacheng/.pyenv/versions/3.11.5/envs/ae/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/yuhuacheng/.pyenv/versions/3.11.5/envs/ae/lib/python3.11/site-packages/transformers/models/encodec/modeling_encodec.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at model/roberta_finetuned and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using evice:  mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from src.modules.clap_model import CLAPModel\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "model = CLAPModel.from_pretrained(\"yuhuacheng/clap-musicgen-1sec\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"yuhuacheng/clap-roberta-finetuned\")\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    print('using evice: ', device)\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1049, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>video_url</th>\n",
       "      <th>audio_url</th>\n",
       "      <th>image_url</th>\n",
       "      <th>major_model_version</th>\n",
       "      <th>model_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>prompt</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>is_en</th>\n",
       "      <th>genres</th>\n",
       "      <th>top_genres</th>\n",
       "      <th>caption</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0039ab46-7ed0-4f0d-ab4f-29188497cc2c</td>\n",
       "      <td>https://cdn1.suno.ai/0039ab46-7ed0-4f0d-ab4f-2...</td>\n",
       "      <td>https://cdn1.suno.ai/0039ab46-7ed0-4f0d-ab4f-2...</td>\n",
       "      <td>https://cdn2.suno.ai/image_0039ab46-7ed0-4f0d-...</td>\n",
       "      <td>v3.5</td>\n",
       "      <td>chirp-v3</td>\n",
       "      <td>electric fast-paced rock</td>\n",
       "      <td>a background song for car chasing scene</td>\n",
       "      <td>[Verse]\\nRev the engines hear the roar\\nMetal ...</td>\n",
       "      <td>True</td>\n",
       "      <td>['rock']</td>\n",
       "      <td>['rock']</td>\n",
       "      <td>The music with styles or genres of electric fa...</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0047cdda-d7fe-4b5c-b675-63f9caa1e7da</td>\n",
       "      <td>https://cdn1.suno.ai/0047cdda-d7fe-4b5c-b675-6...</td>\n",
       "      <td>https://cdn1.suno.ai/0047cdda-d7fe-4b5c-b675-6...</td>\n",
       "      <td>https://cdn2.suno.ai/image_0047cdda-d7fe-4b5c-...</td>\n",
       "      <td>v3.5</td>\n",
       "      <td>chirp-v3</td>\n",
       "      <td>pop hip hop female voice</td>\n",
       "      <td>Hip hop, pop song about liking apples, female ...</td>\n",
       "      <td>[Verse]\\nGot a shiny red delight\\nIn my hand i...</td>\n",
       "      <td>True</td>\n",
       "      <td>['pop']</td>\n",
       "      <td>['pop']</td>\n",
       "      <td>The music with styles or genres of pop hip hop...</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>006d173d-dba9-4811-aaad-caa3662d48a3</td>\n",
       "      <td>https://cdn1.suno.ai/006d173d-dba9-4811-aaad-c...</td>\n",
       "      <td>https://cdn1.suno.ai/006d173d-dba9-4811-aaad-c...</td>\n",
       "      <td>https://cdn2.suno.ai/image_006d173d-dba9-4811-...</td>\n",
       "      <td>v3.5</td>\n",
       "      <td>chirp-v3</td>\n",
       "      <td>collaborative hip-hop</td>\n",
       "      <td>I want this song to have rhyme and a rap that ...</td>\n",
       "      <td>[Verse]\\nStep into the ring, mics swing, hands...</td>\n",
       "      <td>True</td>\n",
       "      <td>['hip-hop']</td>\n",
       "      <td>['hip-hop/rap']</td>\n",
       "      <td>The music with styles or genres of collaborati...</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>00831752-ac48-4201-afc8-d15d2ab3b2fc</td>\n",
       "      <td>https://cdn1.suno.ai/00831752-ac48-4201-afc8-d...</td>\n",
       "      <td>https://cdn1.suno.ai/00831752-ac48-4201-afc8-d...</td>\n",
       "      <td>https://cdn2.suno.ai/image_00831752-ac48-4201-...</td>\n",
       "      <td>v3.5</td>\n",
       "      <td>chirp-v3</td>\n",
       "      <td>melodic acoustic country</td>\n",
       "      <td>a country song about tommy pace having finger ...</td>\n",
       "      <td>[Verse]\\nIn a town where the shadows loom long...</td>\n",
       "      <td>True</td>\n",
       "      <td>['country']</td>\n",
       "      <td>['country']</td>\n",
       "      <td>The music with styles or genres of melodic aco...</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>00986d4e-7e3d-408a-9d15-13c3dcf33e13</td>\n",
       "      <td>https://cdn1.suno.ai/00986d4e-7e3d-408a-9d15-1...</td>\n",
       "      <td>https://cdn1.suno.ai/00986d4e-7e3d-408a-9d15-1...</td>\n",
       "      <td>https://cdn2.suno.ai/image_00986d4e-7e3d-408a-...</td>\n",
       "      <td>v3.5</td>\n",
       "      <td>chirp-v3</td>\n",
       "      <td>smooth electronic edm</td>\n",
       "      <td>A smooth edm song about a cozy rainy day</td>\n",
       "      <td>[Verse]\\nGlistening on the window pane\\nRaindr...</td>\n",
       "      <td>True</td>\n",
       "      <td>['electronic']</td>\n",
       "      <td>['electronic']</td>\n",
       "      <td>The music with styles or genres of smooth elec...</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "24  0039ab46-7ed0-4f0d-ab4f-29188497cc2c   \n",
       "33  0047cdda-d7fe-4b5c-b675-63f9caa1e7da   \n",
       "53  006d173d-dba9-4811-aaad-caa3662d48a3   \n",
       "60  00831752-ac48-4201-afc8-d15d2ab3b2fc   \n",
       "71  00986d4e-7e3d-408a-9d15-13c3dcf33e13   \n",
       "\n",
       "                                            video_url  \\\n",
       "24  https://cdn1.suno.ai/0039ab46-7ed0-4f0d-ab4f-2...   \n",
       "33  https://cdn1.suno.ai/0047cdda-d7fe-4b5c-b675-6...   \n",
       "53  https://cdn1.suno.ai/006d173d-dba9-4811-aaad-c...   \n",
       "60  https://cdn1.suno.ai/00831752-ac48-4201-afc8-d...   \n",
       "71  https://cdn1.suno.ai/00986d4e-7e3d-408a-9d15-1...   \n",
       "\n",
       "                                            audio_url  \\\n",
       "24  https://cdn1.suno.ai/0039ab46-7ed0-4f0d-ab4f-2...   \n",
       "33  https://cdn1.suno.ai/0047cdda-d7fe-4b5c-b675-6...   \n",
       "53  https://cdn1.suno.ai/006d173d-dba9-4811-aaad-c...   \n",
       "60  https://cdn1.suno.ai/00831752-ac48-4201-afc8-d...   \n",
       "71  https://cdn1.suno.ai/00986d4e-7e3d-408a-9d15-1...   \n",
       "\n",
       "                                            image_url major_model_version  \\\n",
       "24  https://cdn2.suno.ai/image_0039ab46-7ed0-4f0d-...                v3.5   \n",
       "33  https://cdn2.suno.ai/image_0047cdda-d7fe-4b5c-...                v3.5   \n",
       "53  https://cdn2.suno.ai/image_006d173d-dba9-4811-...                v3.5   \n",
       "60  https://cdn2.suno.ai/image_00831752-ac48-4201-...                v3.5   \n",
       "71  https://cdn2.suno.ai/image_00986d4e-7e3d-408a-...                v3.5   \n",
       "\n",
       "   model_name                      tags  \\\n",
       "24   chirp-v3  electric fast-paced rock   \n",
       "33   chirp-v3  pop hip hop female voice   \n",
       "53   chirp-v3     collaborative hip-hop   \n",
       "60   chirp-v3  melodic acoustic country   \n",
       "71   chirp-v3     smooth electronic edm   \n",
       "\n",
       "                                               prompt  \\\n",
       "24            a background song for car chasing scene   \n",
       "33  Hip hop, pop song about liking apples, female ...   \n",
       "53  I want this song to have rhyme and a rap that ...   \n",
       "60  a country song about tommy pace having finger ...   \n",
       "71           A smooth edm song about a cozy rainy day   \n",
       "\n",
       "                                               lyrics  is_en          genres  \\\n",
       "24  [Verse]\\nRev the engines hear the roar\\nMetal ...   True        ['rock']   \n",
       "33  [Verse]\\nGot a shiny red delight\\nIn my hand i...   True         ['pop']   \n",
       "53  [Verse]\\nStep into the ring, mics swing, hands...   True     ['hip-hop']   \n",
       "60  [Verse]\\nIn a town where the shadows loom long...   True     ['country']   \n",
       "71  [Verse]\\nGlistening on the window pane\\nRaindr...   True  ['electronic']   \n",
       "\n",
       "         top_genres                                            caption split  \n",
       "24         ['rock']  The music with styles or genres of electric fa...  eval  \n",
       "33          ['pop']  The music with styles or genres of pop hip hop...  eval  \n",
       "53  ['hip-hop/rap']  The music with styles or genres of collaborati...  eval  \n",
       "60      ['country']  The music with styles or genres of melodic aco...  eval  \n",
       "71   ['electronic']  The music with styles or genres of smooth elec...  eval  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/train_10000_split.csv\")\n",
    "# eval_data = data[data['split'] == 'eval'].sample(100, random_state=42)\n",
    "eval_data = data[data['split'] == 'eval']\n",
    "\n",
    "print(eval_data.shape)\n",
    "eval_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the waveforms and produce a dataset list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1049/1049 [00:00<00:00, 141696.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All downloads complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1049/1049 [00:35<00:00, 29.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total TrainingSample items: 1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.utils import parallel_download\n",
    "from src.utils import parallel_load_audio\n",
    "from src.preprocessor import AudioPreprocessor\n",
    "\n",
    "audio_dir = 'data/audios'\n",
    "max_workers = 4\n",
    "parallel_download(eval_data, audio_dir, max_workers=max_workers)\n",
    "\n",
    "ap = AudioPreprocessor(\n",
    "    resample_rate=32000, # sample rate configured for the pretrained EnCodec from MusicGen model\n",
    "    to_mono=True,\n",
    "    sec_to_sample=1,\n",
    "    start_sec=10,\n",
    "    chunk_duration=1,\n",
    ")\n",
    "\n",
    "all_dataset_list = parallel_load_audio(\n",
    "    train_data=eval_data,\n",
    "    audio_dir=audio_dir,\n",
    "    ap=ap,\n",
    "    max_workers=max_workers\n",
    ")\n",
    "\n",
    "print(f\"Total TrainingSample items: {len(all_dataset_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kh/697wjl7x0159ddsq9mn41zlc0000gn/T/ipykernel_54305/4093555243.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython.display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def generate_iframe_table(source_id, derived_ids):\n",
    "    # Start the table with a header row\n",
    "    html_code = \"\"\"\n",
    "    <table border=\"1\" cellspacing=\"5\" cellpadding=\"5\">\n",
    "        <tr>\n",
    "            <th>Source</th>\n",
    "    \"\"\"\n",
    "\n",
    "    # Add headers dynamically for each derived ID\n",
    "    for i in range(len(derived_ids)):\n",
    "        html_code += f\"<th>Top {i+1}</th>\"\n",
    "    \n",
    "    html_code += \"</tr>\\n\"\n",
    "\n",
    "    # Add the source row\n",
    "    html_code += f\"\"\"\n",
    "        <tr>\n",
    "            <td><iframe src=\"https://suno.com/embed/{source_id}\" width=\"400\" height=\"200\"></iframe></td>\n",
    "    \"\"\"\n",
    "\n",
    "    # Add iframes for derived IDs\n",
    "    for derived_id in derived_ids:\n",
    "        html_code += f'<td><iframe src=\"https://suno.com/embed/{derived_id}\" width=\"400\" height=\"200\"></iframe></td>'\n",
    "    \n",
    "    html_code += \"</tr>\\n</table>\"\n",
    "\n",
    "    # Display the table in Jupyter Notebook\n",
    "    display(HTML(html_code))\n",
    "\n",
    "def generate_iframe_table_with_source_tag(source_tag, track_ids):\n",
    "    # Start the table with a header row\n",
    "    html_code = \"\"\"\n",
    "    <table border=\"1\" cellspacing=\"5\" cellpadding=\"5\">\n",
    "        <tr>\n",
    "            <th style=\"width: 200px;\">Source</th>\n",
    "    \"\"\"\n",
    "\n",
    "    # Add headers dynamically for each track ID\n",
    "    for i in range(len(track_ids)):\n",
    "        html_code += f\"<th>Top {i+1}</th>\"\n",
    "    \n",
    "    html_code += \"</tr>\\n\"\n",
    "\n",
    "    # Add the source tag as text (instead of an iframe)\n",
    "    html_code += f\"\"\"\n",
    "        <tr>\n",
    "            <td style=\"width: 200px;\"><strong>{source_tag}</strong></td>\n",
    "    \"\"\"\n",
    "\n",
    "    # Add iframes for the track IDs\n",
    "    for track_id in track_ids:\n",
    "        html_code += f'<td><iframe src=\"https://suno.com/embed/{track_id}\" width=\"400\" height=\"200\"></iframe></td>'\n",
    "    \n",
    "    html_code += \"</tr>\\n</table>\"\n",
    "\n",
    "    # Display the table in Jupyter Notebook\n",
    "    display(HTML(html_code))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽµ **Audio-to-Audio Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "from src.utils import TrainingSample\n",
    "\n",
    "def compute_audio_embeddings(dataset_list: List[TrainingSample], model: CLAPModel, device: str, batch_size: int = 8) -> Dict[str, torch.Tensor]:\n",
    "    audio_embeddings = {}\n",
    "    model.eval()\n",
    "    \n",
    "    # Group samples by track_id\n",
    "    track_batches = {}\n",
    "    for d in dataset_list:\n",
    "        track_id = d.id\n",
    "        if track_id not in track_batches:\n",
    "            track_batches[track_id] = []\n",
    "        track_batches[track_id].append(d.waveform.unsqueeze(0))  # Add batch dimension\n",
    "    \n",
    "    for track_id, waveforms in track_batches.items():\n",
    "        waveforms = torch.cat(waveforms, dim=0).to(device)  # Stack all waveforms for this track_id\n",
    "        \n",
    "        batched_embeddings = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, waveforms.size(0), batch_size):\n",
    "                batch_waveforms = waveforms[i:i+batch_size]\n",
    "                batch_embeddings = model.audio_encoder([track_id] * batch_waveforms.size(0), batch_waveforms)  # Replicate track_id\n",
    "                batched_embeddings.append(batch_embeddings)\n",
    "        \n",
    "        # Concatenate all batches for this track_id\n",
    "        audio_embeddings[track_id] = torch.cat(batched_embeddings, dim=0)\n",
    "    \n",
    "    return audio_embeddings\n",
    "\n",
    "\n",
    "def compute_top_k_similar_tracks(audio_embeddings: Dict[str, torch.Tensor], top_k: int = 5) -> Dict[str, List[str]]:\n",
    "    track_ids = list(audio_embeddings.keys())\n",
    "    embeddings = torch.stack([audio_embeddings[tid].mean(dim=0) for tid in track_ids])  # Compute mean embedding per track\n",
    "    \n",
    "    # Normalize embeddings for cosine similarity\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    \n",
    "    # Compute cosine similarity matrix\n",
    "    similarity_matrix = torch.mm(embeddings, embeddings.T)\n",
    "    \n",
    "    top_k_similar_tracks = {}\n",
    "    for idx, track_id in enumerate(track_ids):\n",
    "        similarities = similarity_matrix[idx]\n",
    "        top_k_indices = similarities.topk(top_k + 1).indices[1:].tolist()  # Exclude self-similarity\n",
    "        top_k_similar_tracks[track_id] = [track_ids[i] for i in top_k_indices]\n",
    "    \n",
    "    return top_k_similar_tracks\n",
    "\n",
    "\n",
    "audio_embeddings = compute_audio_embeddings(all_dataset_list, model, device, batch_size=16)\n",
    "tok_k_audio_to_audio = compute_top_k_similar_tracks(audio_embeddings, top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 - Source Tags: \"melodic acoustic country\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table border=\"1\" cellspacing=\"5\" cellpadding=\"5\">\n",
       "        <tr>\n",
       "            <th>Source</th>\n",
       "    <th>Top 1</th><th>Top 2</th><th>Top 3</th></tr>\n",
       "\n",
       "        <tr>\n",
       "            <td><iframe src=\"https://suno.com/embed/00831752-ac48-4201-afc8-d15d2ab3b2fc\" width=\"400\" height=\"200\"></iframe></td>\n",
       "    <td><iframe src=\"https://suno.com/embed/83f1554e-7091-4023-8e29-d4b3ada7b421\" width=\"400\" height=\"200\"></iframe></td><td><iframe src=\"https://suno.com/embed/011fc464-80c3-4b18-b930-7bef81242b10\" width=\"400\" height=\"200\"></iframe></td><td><iframe src=\"https://suno.com/embed/2e3a4e27-6ce8-4d79-b555-e9c6452e1866\" width=\"400\" height=\"200\"></iframe></td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "id = \"00831752-ac48-4201-afc8-d15d2ab3b2fc\"\n",
    "\n",
    "generate_iframe_table(id, tok_k_audio_to_audio[id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 - Source Tags: \"soft mellow lofi jazz hop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table border=\"1\" cellspacing=\"5\" cellpadding=\"5\">\n",
       "        <tr>\n",
       "            <th>Source</th>\n",
       "    <th>Top 1</th><th>Top 2</th><th>Top 3</th></tr>\n",
       "\n",
       "        <tr>\n",
       "            <td><iframe src=\"https://suno.com/embed/0a4b6d10-2c82-4937-a31a-8c9158236dad\" width=\"400\" height=\"200\"></iframe></td>\n",
       "    <td><iframe src=\"https://suno.com/embed/0d3957e6-ce71-4f3e-8201-5e296eaaf660\" width=\"400\" height=\"200\"></iframe></td><td><iframe src=\"https://suno.com/embed/0fcb8100-b319-4ff1-9f52-e019d49aefbd\" width=\"400\" height=\"200\"></iframe></td><td><iframe src=\"https://suno.com/embed/96ebfa55-ff98-4611-815d-3c9b1bfc1f0a\" width=\"400\" height=\"200\"></iframe></td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "id = \"0a4b6d10-2c82-4937-a31a-8c9158236dad\"\n",
    "\n",
    "generate_iframe_table(id, tok_k_audio_to_audio[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table border=\"1\" cellspacing=\"5\" cellpadding=\"5\">\n",
       "        <tr>\n",
       "            <th>Source</th>\n",
       "    <th>Top 1</th><th>Top 2</th><th>Top 3</th></tr>\n",
       "\n",
       "        <tr>\n",
       "            <td><iframe src=\"https://suno.com/embed/09f12dd0-fa1d-4efa-ba89-25af6009f08c\" width=\"400\" height=\"200\"></iframe></td>\n",
       "    <td><iframe src=\"https://suno.com/embed/83ab5cda-4f13-4e99-a525-091cecad7eb6\" width=\"400\" height=\"200\"></iframe></td><td><iframe src=\"https://suno.com/embed/cdf6e51c-b346-407d-8267-1c8d05ee6d6d\" width=\"400\" height=\"200\"></iframe></td><td><iframe src=\"https://suno.com/embed/570d1fe5-a621-4ed9-9e41-63a37def5b65\" width=\"400\" height=\"200\"></iframe></td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "id = \"09f12dd0-fa1d-4efa-ba89-25af6009f08c\"\n",
    "\n",
    "generate_iframe_table(id, tok_k_audio_to_audio[id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¬ **Text-to-Audio Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== looking for similar audio from text embeddings ====\n",
    "sample_captions = [\n",
    "    'positive jazz',\n",
    "    'chill house',\n",
    "    'gangsta rap',\n",
    "    'dark metal'\n",
    "    # try it with your own captions!\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokenized_captions = tokenizer(list(sample_captions), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    tokenized_captions = {k: v.to(device) for k, v in tokenized_captions.items()}\n",
    "    sample_text_embs = model.text_encoder(ids=None, **tokenized_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <table border=\"1\" cellspacing=\"5\" cellpadding=\"5\">\n",
       "        <tr>\n",
       "            <th style=\"width: 200px;\">Source</th>\n",
       "    <th>Top 1</th><th>Top 2</th><th>Top 3</th></tr>\n",
       "\n",
       "        <tr>\n",
       "            <td style=\"width: 200px;\"><strong>positive jazz</strong></td>\n",
       "    <td><iframe src=\"https://suno.com/embed/5522db8c-c775-4bf0-8da8-af94b9c05fd0\" width=\"400\" height=\"200\"></iframe></td><td><iframe src=\"https://suno.com/embed/92679eeb-bbc6-4da2-9ec1-3742e1b2b77b\" width=\"400\" height=\"200\"></iframe></td><td><iframe src=\"https://suno.com/embed/22c3f959-8df1-4080-b7f6-11d0a886fff9\" width=\"400\" height=\"200\"></iframe></td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <table border=\"1\" cellspacing=\"5\" cellpadding=\"5\">\n",
       "        <tr>\n",
       "            <th style=\"width: 200px;\">Source</th>\n",
       "    <th>Top 1</th><th>Top 2</th><th>Top 3</th></tr>\n",
       "\n",
       "        <tr>\n",
       "            <td style=\"width: 200px;\"><strong>chill house</strong></td>\n",
       "    <td><iframe src=\"https://suno.com/embed/5522db8c-c775-4bf0-8da8-af94b9c05fd0\" width=\"400\" height=\"200\"></iframe></td><td><iframe src=\"https://suno.com/embed/292f70bc-8bec-4bfa-86f2-8f2e061ed202\" width=\"400\" height=\"200\"></iframe></td><td><iframe src=\"https://suno.com/embed/a1e5f163-efd3-46a6-9394-8f0213b63376\" width=\"400\" height=\"200\"></iframe></td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <table border=\"1\" cellspacing=\"5\" cellpadding=\"5\">\n",
       "        <tr>\n",
       "            <th style=\"width: 200px;\">Source</th>\n",
       "    <th>Top 1</th><th>Top 2</th><th>Top 3</th></tr>\n",
       "\n",
       "        <tr>\n",
       "            <td style=\"width: 200px;\"><strong>gangsta rap</strong></td>\n",
       "    <td><iframe src=\"https://suno.com/embed/660b76ff-39a0-4a0b-b703-1e7e82473a95\" width=\"400\" height=\"200\"></iframe></td><td><iframe src=\"https://suno.com/embed/18136acd-6b7d-4808-83f0-db4acc219824\" width=\"400\" height=\"200\"></iframe></td><td><iframe src=\"https://suno.com/embed/697c4e78-e420-4bd5-8834-7bb92166377a\" width=\"400\" height=\"200\"></iframe></td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <table border=\"1\" cellspacing=\"5\" cellpadding=\"5\">\n",
       "        <tr>\n",
       "            <th style=\"width: 200px;\">Source</th>\n",
       "    <th>Top 1</th><th>Top 2</th><th>Top 3</th></tr>\n",
       "\n",
       "        <tr>\n",
       "            <td style=\"width: 200px;\"><strong>dark metal</strong></td>\n",
       "    <td><iframe src=\"https://suno.com/embed/1855d353-f0ed-43d9-bf1e-5579b504172c\" width=\"400\" height=\"200\"></iframe></td><td><iframe src=\"https://suno.com/embed/1f7e878d-fd6e-419b-b463-45c9ac5edc00\" width=\"400\" height=\"200\"></iframe></td><td><iframe src=\"https://suno.com/embed/28cdc354-e504-4d0c-95aa-f5f70d9a0772\" width=\"400\" height=\"200\"></iframe></td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def find_top_k_similar_audio(text_embeddings, text_list, audio_dict, k=5):\n",
    "    # Stack all audio embeddings into a single tensor of shape (num_audio, 1024)\n",
    "    audio_ids = list(audio_dict.keys())\n",
    "    audio_embeddings = torch.cat([audio_dict[a_id] for a_id in audio_ids], dim=0)  # Shape (num_audio, 1024)\n",
    "\n",
    "    # Normalize text and audio embeddings to unit vectors\n",
    "    text_embeddings = torch.nn.functional.normalize(text_embeddings, p=2, dim=1)  # (B, 1024)\n",
    "    audio_embeddings = torch.nn.functional.normalize(audio_embeddings, p=2, dim=1)  # (num_audio, 1024)\n",
    "\n",
    "    # Compute cosine similarity: (B, 1024) @ (1024, num_audio) -> (B, num_audio)\n",
    "    similarity_matrix = torch.matmul(text_embeddings, audio_embeddings.T)\n",
    "\n",
    "    # Get top k indices for each text example\n",
    "    top_k_indices = torch.topk(similarity_matrix, k, dim=1).indices  # (B, k)\n",
    "\n",
    "    # Map results to dictionary\n",
    "    text_to_audio_mapping = {\n",
    "        text_list[i]: [audio_ids[idx] for idx in top_k_indices[i].tolist()]\n",
    "        for i in range(len(text_list))\n",
    "    }\n",
    "\n",
    "    return text_to_audio_mapping\n",
    "\n",
    "tok_k_text_to_audio = find_top_k_similar_audio(sample_text_embs, sample_captions, audio_embeddings, 3)\n",
    "for source_tags in sample_captions:\n",
    "    generate_iframe_table_with_source_tag(source_tags, tok_k_text_to_audio[source_tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
